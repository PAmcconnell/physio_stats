                    """
                    # * Old method of artifact window correction 
                    
                    # Estimate the number of beats within the artifact window using the local average R-R interval
                    estimated_beats_artifact_window = int(np.round(artifact_duration / local_rr_interval_seconds))
                    logging.info(f"Estimated number of beats in artifact window: {estimated_beats_artifact_window}")

                    # FIXME: Not optimal fitting choosing between estimated and actual beats
                    # If the estimated number of beats is not fitting well, adjust by comparing with the artifact duration
                    actual_beats_artifact_window = estimated_beats_artifact_window if (estimated_beats_artifact_window * local_rr_interval_samples <= artifact_window_samples) else estimated_beats_artifact_window - 1
                    logging.info(f"Adjusted estimated number of beats in artifact window: {actual_beats_artifact_window}")

                    # Ensure mean_heartbeat is a flat NumPy array
                    if isinstance(mean_heartbeat, np.ndarray):
                        mean_heartbeat_array = mean_heartbeat_trimmed.flatten()
                    else:
                        mean_heartbeat_array = mean_heartbeat_trimmed.values.flatten()

                    # Repeat the average beat shape to fill the adjusted estimated missing beats
                    replicated_beats = np.tile(mean_heartbeat_array, actual_beats_artifact_window)
                    logging.info(f"Replicated beats length: {len(replicated_beats)} samples")

                    # Adjust the length of replicated beats to match the artifact window duration by interpolation
                    x_old = np.linspace(0, 1, len(replicated_beats))
                    logging.info(f"Old length of replicated beats: {len(replicated_beats)} samples")
                    x_new = np.linspace(0, 1, expected_slice_length) 
                    logging.info(f"New length of replicated beats: {expected_slice_length} samples")
                    replicated_beats = np.interp(x_new, x_old, replicated_beats)  # Adjust the length of replicated beats
                    logging.info(f"Replicated beats length (interpolated): {len(replicated_beats)} samples")
                    x_old = x_new # Update x_old to match the new length
                    logging.info(f"Updated x_old to match the new length: {len(x_old)} samples")
                    
                    # To create a smooth transition, generate a tapered window for cross-fading
                    fade_length = int(sampling_rate * 0.05)  # 5% of a second, adjust as needed
                    logging.info(f"Fade length for cross-fading: {fade_length} samples")
                    taper_window = np.linspace(0, 1, fade_length)
                    logging.info("Created taper window for cross-fading.")

                    # Apply cross-fade at the beginning of the artifact window
                    start_faded = (1 - taper_window) * valid_ppg[true_start:true_start + fade_length] + taper_window * replicated_beats[:fade_length]

                    # Apply cross-fade at the end of the artifact window
                    end_faded = (1 - taper_window) * replicated_beats[-fade_length:] + taper_window * valid_ppg[true_start + artifact_window_samples - fade_length:true_start + artifact_window_samples]
                
                    # Prepare for replacement, Calculate the total length of the section to be replaced in valid_ppg
                    total_replacement_length = artifact_window_samples 
                    logging.info(f"Total length of the section to be replaced: {total_replacement_length} samples")

                    # The middle segment is adjusted to fit exactly after considering start and end fades
                    middle_segment = replicated_beats[fade_length:-fade_length]
                    logging.info(f"Middle segment length: {len(middle_segment)} samples")
                    
                    # Generate the concatenated array for replacement correctly within the artifact window
                    concatenated_beats = np.concatenate((start_faded, middle_segment, end_faded))
                    concatenated_beats_length = len(concatenated_beats)
                    logging.info(f"Concatenated beats length: {concatenated_beats_length} samples")

                    # Get the y values (amplitudes) from concatenated_beats and their corresponding x indices
                    y_values = concatenated_beats
                    x_indices = np.arange(len(y_values))

                    # Find the indices of the top actual_beats_artifact_window (N)# of maxima
                    # argsort sorts in ascending order, so we take the last N indices for the highest values
                    top_maxima_indices = np.argsort(y_values)[-actual_beats_artifact_window:]

                    # Since we're interested in the exact x (sample indices) of these maxima
                    peaks_indices = x_indices[top_maxima_indices]

                    # Sort the x indices to maintain temporal order
                    peaks_indices = np.sort(peaks_indices)
                    
                    # Perform peak detection on the concatenated_beats within the boundaries
                    boundary_indices = [start, end] 
                    logging.info(f"Boundary indices for peak detection: {boundary_indices}")
                    
                    #! An error was introduced here, the indices were not adjusted to the concatenated beats
                    # FIXME: Is this fixed? PAMcConnell 2024-05-13
                    nadir_indices = [true_start, true_end] 
                    logging.info(f"Nadir indices for peak detection: {nadir_indices}")
                    
                    peaks_indices = [index + nadir_indices[0] for index in peaks_indices]
    
                    # Convert peaks_indices to a NumPy array if not already
                    peaks_indices = np.array(peaks_indices)

                    # Explicitly include boundary peaks if not already detected
                    if start not in peaks_indices:
                        peaks_indices = np.append(peaks_indices, start)
                        logging.info(f"Including start boundary peak: {start}")
                    if end not in peaks_indices:
                        peaks_indices = np.append(peaks_indices, end)
                        logging.info(f"Including end boundary peak: {end}")

                    # Ensure the peaks_indices are sorted since we might have appended boundary indices
                    peaks_indices = np.sort(peaks_indices)
                    logging.info(f"Including boundary peaks, adjusted peaks indices sorted: {peaks_indices}")

                    # Calculate the R-R intervals from the detected peaks
                    concatenated_rr_intervals = np.diff(peaks_indices) / sampling_rate * 1000
                    logging.info(f"R-R intervals from the detected peaks: {concatenated_rr_intervals}")

                    # Compute the mean and standard deviation of these intervals
                    concatenated_rr_mean = np.mean(concatenated_rr_intervals)
                    logging.info(f"Mean R-R interval within concatenated beats: {concatenated_rr_mean} milliseconds")
                    logging.info(f"Average Local R-R Interval: {local_rr_interval} milliseconds")
                    concatenated_rr_std = np.std(concatenated_rr_intervals)
                    logging.info(f"Standard deviation of R-R intervals within concatenated beats: {concatenated_rr_std}")
                    logging.info(f"Standard deviation of local R-R intervals: {std_local_rr_interval} milliseconds")

                    # Calculate the difference in mean R-R intervals and decide if adjustment is needed
                    mean_rr_difference = abs(local_rr_interval - concatenated_rr_mean)
                    logging.info(f"Difference in mean R-R intervals: {mean_rr_difference} milliseconds")
                    
                    # Calculate deviations of each R-R interval from the local mean
                    rr_deviations = np.abs(concatenated_rr_intervals - local_rr_interval)
                    logging.info(f"Individual R-R interval deviations: {rr_deviations}")

                    # Define a threshold for significant deviation
                    deviation_threshold = 25  # milliseconds

                    # Check if any individual R-R intervals deviate significantly from the local mean
                    significant_deviation = np.any(rr_deviations > deviation_threshold)
                    if significant_deviation:
                        logging.info("Significant individual R-R interval deviation detected, requiring adjustment.")
                        
                        # Determine stretch or compression factor based on whether the mean R-R interval of concatenated beats is longer or shorter than desired
                        if concatenated_rr_mean > local_rr_interval:
                            logging.info("Concatenated beats have longer intervals, compressing them slightly.")
                            # If concatenated beats have longer intervals, compress them slightly
                            stretch_factor = local_rr_interval / concatenated_rr_mean
                            logging.info(f"Stretch factor: {stretch_factor}")
                        else:
                            logging.info("Concatenated beats have shorter intervals, stretching them slightly.")
                            # If concatenated beats have shorter intervals, stretch them slightly
                            stretch_factor = concatenated_rr_mean / local_rr_interval
                            logging.info(f"Stretch factor: {stretch_factor}")

                        # Adjust 'x_new' for stretching or compressing the average beat shape
                        x_old = np.linspace(0, 1, len(mean_heartbeat_array))
                        logging.info(f"Old length of average beat: {len(x_old)} samples")
                        x_new_adjusted = np.linspace(0, 1, int(len(mean_heartbeat_array) * stretch_factor))
                        logging.info(f"New length of average beat after adjustment: {len(x_new_adjusted)} samples")

                        # Interpolate the average beat to adjust its length
                        adjusted_mean_heartbeat = np.interp(x_new_adjusted, x_old, mean_heartbeat_array)
                        logging.info(f"Adjusted average beat length: {len(adjusted_mean_heartbeat)} samples")

                        # Calculate the total duration in seconds that the artifact window should cover
                        artifact_window_duration_seconds = expected_slice_length / sampling_rate
                        logging.info(f"Artifact window duration in seconds: {artifact_window_duration_seconds} seconds")

                        # Calculate the mean R-R interval for the estimated and actual number of beats
                        mean_rr_estimated = artifact_window_duration_seconds / estimated_beats_artifact_window * 1000  # Convert to milliseconds
                        logging.info(f"Mean R-R interval for first estimated number of beats: {mean_rr_estimated} milliseconds")
                        mean_rr_actual = artifact_window_duration_seconds / actual_beats_artifact_window * 1000  # Convert to milliseconds
                        logging.info(f"Mean R-R interval for adjusted number of beats (actual_beats_artifact_window): {mean_rr_actual} milliseconds")
                        
                        # Determine the deviation from the local_rr_interval for each
                        deviation_estimated = abs(local_rr_interval - mean_rr_estimated)
                        logging.info(f"Deviation from local R-R interval for estimated number of beats: {deviation_estimated} milliseconds")
                        deviation_actual = abs(local_rr_interval - mean_rr_actual)
                        logging.info(f"Deviation from local R-R interval for adjusted number of beats: {deviation_actual} milliseconds")

                        # Choose the option with the smallest deviation
                        if deviation_estimated <= deviation_actual:
                            logging.info("Estimated number of beats has smaller deviation from local R-R interval.")
                            chosen_beats_artifact_window = estimated_beats_artifact_window
                            logging.info("Using estimated_beats_artifact_window for replication.")
                        else:
                            logging.info("Adjusted number of beats has smaller deviation from local R-R interval.")
                            chosen_beats_artifact_window = actual_beats_artifact_window
                            logging.info("Using actual_beats_artifact_window for replication.")

                        # Now replicate the adjusted average beat according to the chosen option
                        replicated_adjusted_beats = np.tile(adjusted_mean_heartbeat, chosen_beats_artifact_window)
                        logging.info(f"Replicated adjusted beats length: {len(replicated_adjusted_beats)} samples")
                        
                        # Adjust the length of replicated beats to exactly match the artifact window's duration
                        # Use interpolation to fit the replicated beats into the expected_slice_length
                        x_old_replicated = np.linspace(0, 1, len(replicated_adjusted_beats))
                        logging.info(f"Old length of replicated adjusted beats: {len(x_old_replicated)} samples")
                        x_new_replicated = np.linspace(0, 1, expected_slice_length)
                        logging.info(f"New length of replicated adjusted beats: {len(x_new_replicated)} samples")
                        adjusted_replicated_beats = np.interp(x_new_replicated, x_old_replicated, replicated_adjusted_beats)
                        logging.info(f"Adjusted replicated beats length: {len(adjusted_replicated_beats)} samples")

                        # Prepare adjusted beats for insertion
                        ## Apply cross-fade at the beginning and end of the artifact window for a smooth transition
                        start_faded = (1 - taper_window) * valid_ppg[true_start:true_start + fade_length] + taper_window * adjusted_replicated_beats[:fade_length]
                        logging.info(f"Start faded: {len(start_faded)} samples")
                        end_faded = (1 - taper_window) * adjusted_replicated_beats[-fade_length:] + taper_window * valid_ppg[true_start + artifact_window_samples - fade_length:true_start + artifact_window_samples]
                        logging.info(f"End faded: {len(end_faded)} samples")
                        middle_segment_adjusted = adjusted_replicated_beats[fade_length:-fade_length]
                        logging.info(f"Middle segment adjusted: {len(middle_segment_adjusted)} samples")
                        corrected_signal = np.concatenate((start_faded, middle_segment_adjusted, end_faded))
                        logging.info(f"Corrected signal length: {len(corrected_signal)} samples")
                        
                        #! Insert peak detection again on the corrected signal including boundary peaks to get the asymmetrical first and last r-r intervals
                        
                        # Get the y values (amplitudes) from concatenated_beats and their corresponding x indices
                        y_values = corrected_signal
                        x_indices = np.arange(len(y_values))

                        # Find the indices of the top actual_beats_artifact_window (N)# of maxima
                        # argsort sorts in ascending order, so we take the last N indices for the highest values
                        top_maxima_indices = np.argsort(y_values)[-actual_beats_artifact_window:]

                        # Since we're interested in the exact x (sample indices) of these maxima
                        peaks_indices = x_indices[top_maxima_indices]

                        # Sort the x indices to maintain temporal order
                        peaks_indices = np.sort(peaks_indices)
                        
                        # Perform peak detection on the concatenated_beats within the boundaries
                        boundary_indices = [start, end]  # Use the correct indices from your context
                        logging.info(f"Boundary indices for peak detection: {boundary_indices}")
                        
                        nadir_indices = [true_start, true_end] 
                        logging.info(f"Nadir indices for peak detection: {nadir_indices}")
                        
                        peaks_indices = [index + nadir_indices[0] for index in peaks_indices]
        
                        # Convert peaks_indices to a NumPy array if not already
                        peaks_indices = np.array(peaks_indices)

                        # Explicitly include boundary peaks if not already detected
                        if start not in peaks_indices:
                            peaks_indices = np.append(peaks_indices, start)
                            logging.info(f"Including start boundary peak: {start}")
                        if end not in peaks_indices:
                            peaks_indices = np.append(peaks_indices, end)
                            logging.info(f"Including end boundary peak: {end}")

                        # Ensure the peaks_indices are sorted since we might have appended boundary indices
                        peaks_indices = np.sort(peaks_indices)
                        logging.info(f"Including boundary peaks, adjusted peaks indices sorted: {peaks_indices}")

                        # Calculate the R-R intervals from the detected peaks
                        concatenated_corrected_rr_intervals = np.diff(peaks_indices) / sampling_rate * 1000
                        logging.info(f"R-R intervals from the detected peaks: {concatenated_corrected_rr_intervals}")
                        
                        # Calculate the deviation of the first and last R-R interval from the local mean
                        first_rr_deviation = abs(concatenated_corrected_rr_intervals[0] - local_rr_interval)
                        logging.info(f"First R-R interval deviation: {first_rr_deviation} milliseconds")
                        first_rr_interval = concatenated_corrected_rr_intervals[0]
                        logging.info(f"First R-R interval: {first_rr_interval} milliseconds")
                        last_rr_deviation = abs(concatenated_corrected_rr_intervals[-1] - local_rr_interval)
                        logging.info(f"Last R-R interval deviation: {last_rr_deviation} milliseconds")
                        last_rr_interval = concatenated_corrected_rr_intervals[-1]
                        logging.info(f"Last R-R interval: {last_rr_interval} milliseconds")
                        
                        # Calculate the midpoint index of the first R-R interval
                        midpoint_first_rr = (peaks_indices[1] + peaks_indices[0]) // 2
                        logging.info(f"Midpoint of the first R-R interval: {midpoint_first_rr} samples")
                        
                        # Calculate the target R-R interval (average of first and last)
                        target_rr_interval = (first_rr_interval + last_rr_interval) / 2
                        logging.info(f"Target R-R interval: {target_rr_interval} milliseconds")

                        # Calculate how many samples each interval needs to change to meet the target interval
                        first_adjustment_samples = (first_rr_interval - target_rr_interval) / 1000 * sampling_rate
                        last_adjustment_samples = (last_rr_interval - target_rr_interval) / 1000 * sampling_rate
                        logging.info(f"First interval adjustment in samples: {first_adjustment_samples}")
                        logging.info(f"Last interval adjustment in samples: {last_adjustment_samples}")

                        #! Temporary fix to avoid the phase shift calculation
                        
                        # Calculate the shift required
                        # If first_adjustment_samples is positive, we need to shift left to decrease the first interval
                        # If last_adjustment_samples is negative, we need to shift right to increase the last interval
                        # Adjust by the average of these two values to try and center the adjustment
                        shift_samples = int(round((first_adjustment_samples - last_adjustment_samples) / 2))
                        shift_direction = 'left' if shift_samples > 0 else 'right'
                        shift_samples = abs(shift_samples)
                        logging.info(f"Calculated shift of {shift_samples} samples to the {shift_direction}")

                        # Apply the calculated shift to the signal
                        if shift_direction == 'left':
                            shifted_signal = np.roll(corrected_signal, -shift_samples)
                            shifted_signal[-shift_samples:] = corrected_signal[-1]  # Fill the end with the last value
                        else:
                            shifted_signal = np.roll(corrected_signal, shift_samples)
                            shifted_signal[:shift_samples] = corrected_signal[0]  # Fill the beginning with the first value

                        # Ensure the shifted signal has the correct length to fit into the artifact window
                        shifted_signal = shifted_signal[:len(corrected_signal)]  # Adjust length after the shift
                        valid_ppg[true_start:true_end + 1] = shifted_signal  # Insert the shifted signal into the valid_ppg array
                        logging.info(f"Shifted and adjusted signal inserted with length {len(shifted_signal)}")
                        logging.info(f"Applied a phase shift of {shift_samples} samples to the {shift_direction} to balance the first and last R-R intervals.")
                    else:
                        # If mean R-R interval difference is not significant, no adjustment needed
                        logging.info(f"No significant mean R-R interval difference detected: {mean_rr_difference} milliseconds")    
                        logging.info("No further adjusted artifact correction needed.")  
                        # Insert the first calculation of concatenated beats into the valid_ppg artifact window
                        valid_ppg[true_start:true_end + 1] = concatenated_beats
                        logging.info(f"Concatenated beats successfully assigned to valid_ppg.")
                        """
                    