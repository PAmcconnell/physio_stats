@app.callback(
    [Output('ppg-plot', 'figure'),
     Output('data-store', 'data'),
     Output('peaks-store', 'data'),
     Output('peak-change-store', 'data')],
    [Input('artifact-store', 'data')],
    [State('data-store', 'data'),
     State('peaks-store', 'data')]
)
def correct_artifacts(artifact_data, data_json, valid_peaks):
    logging.info(f"Correct artifacts callback triggered. Artifact data: {artifact_data}")
    
    # Check if there are valid artifacts to process
    if not artifact_data or not any('start' in artifact and 'end' in artifact for artifact in artifact_data):
        logging.info("No valid artifacts to process, skipping callback")
        raise dash.exceptions.PreventUpdate
    
    # Load and process data
    df = pd.read_json(data_json, orient='split')

    # Initialize peak changes tracking
    peak_changes = {'added': 0, 'deleted': 0, 'interpolated_length': 0, 'interpolated_peaks': 0}

    # Process each artifact
    for artifact in artifact_data:
        if 'start' in artifact and 'end' in artifact:
            start, end = artifact['start'], artifact['end']
            # Ensure start and end are within data range
            start = max(0, min(start, len(df) - 1))
            end = max(0, min(end, len(df) - 1))

            if start < end:
                # Extracting data points around the artifact for interpolation
                surrounding_points = 5  # Number of points to include around the artifact
                x_range = df.index[max(start - surrounding_points, 0) : min(end + surrounding_points, len(df))]
                y_range = df['PPG_Clean'][max(start - surrounding_points, 0) : min(end + surrounding_points, len(df))]

                # Cubic Spline interpolation
                cs = CubicSpline(x_range, y_range)
                df.loc[start:end, 'PPG_Clean'] = cs(np.arange(start, end + 1))

                # Estimating the number of beats that would have occurred
                avg_rr_interval = np.mean(np.diff(valid_peaks))
                estimated_beats = int((end - start) / avg_rr_interval)

                # Distribute these beats evenly
                interpolated_peaks = np.linspace(start, end, estimated_beats, endpoint=False).astype(int)

                # Update peak changes
                peak_changes['interpolated_length'] += (end - start)
                peak_changes['interpolated_peaks'] += len(interpolated_peaks)

                # Update the list of valid peaks
                valid_peaks = sorted(set(valid_peaks).difference(set(range(start, end+1))).union(set(interpolated_peaks)))

    # Update the plot with corrected data
    fig = create_figure(df, valid_peaks)

    # Convert the DataFrame back to JSON
    updated_data_json = df.to_json(date_format='iso', orient='split')

    return fig, updated_data_json, valid_peaks, peak_changes